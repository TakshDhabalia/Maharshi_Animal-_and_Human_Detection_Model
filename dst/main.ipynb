{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "194820c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.14.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting roboflow\n",
      "  Downloading roboflow-1.1.66-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\dhaba\\anaconda3\\envs\\mh\\lib\\site-packages (from roboflow) (2025.4.26)\n",
      "Collecting idna==3.7 (from roboflow)\n",
      "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: cycler in c:\\users\\dhaba\\anaconda3\\envs\\mh\\lib\\site-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\dhaba\\anaconda3\\envs\\mh\\lib\\site-packages (from roboflow) (1.4.8)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\dhaba\\anaconda3\\envs\\mh\\lib\\site-packages (from roboflow) (3.7.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\dhaba\\anaconda3\\envs\\mh\\lib\\site-packages (from roboflow) (1.24.3)\n",
      "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
      "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\dhaba\\anaconda3\\envs\\mh\\lib\\site-packages (from roboflow) (11.2.1)\n",
      "Collecting pillow-heif>=0.18.0 (from roboflow)\n",
      "  Downloading pillow_heif-0.22.0-cp311-cp311-win_amd64.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\dhaba\\anaconda3\\envs\\mh\\lib\\site-packages (from roboflow) (2.9.0.post0)\n",
      "Collecting python-dotenv (from roboflow)\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\dhaba\\anaconda3\\envs\\mh\\lib\\site-packages (from roboflow) (2.32.4)\n",
      "Requirement already satisfied: six in c:\\users\\dhaba\\anaconda3\\envs\\mh\\lib\\site-packages (from roboflow) (1.17.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in c:\\users\\dhaba\\anaconda3\\envs\\mh\\lib\\site-packages (from roboflow) (2.4.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\dhaba\\anaconda3\\envs\\mh\\lib\\site-packages (from roboflow) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\dhaba\\anaconda3\\envs\\mh\\lib\\site-packages (from roboflow) (6.0.2)\n",
      "Collecting requests-toolbelt (from roboflow)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting filetype (from roboflow)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\dhaba\\anaconda3\\envs\\mh\\lib\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dhaba\\anaconda3\\envs\\mh\\lib\\site-packages (from matplotlib->roboflow) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dhaba\\anaconda3\\envs\\mh\\lib\\site-packages (from matplotlib->roboflow) (4.58.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dhaba\\anaconda3\\envs\\mh\\lib\\site-packages (from matplotlib->roboflow) (25.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\dhaba\\anaconda3\\envs\\mh\\lib\\site-packages (from matplotlib->roboflow) (3.0.9)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\dhaba\\anaconda3\\envs\\mh\\lib\\site-packages (from requests->roboflow) (3.4.2)\n",
      "Downloading roboflow-1.1.66-py3-none-any.whl (86 kB)\n",
      "Downloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "Downloading opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "   ---------------------------------------- 0.0/38.8 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 2.1/38.8 MB 10.7 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 4.5/38.8 MB 11.2 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 6.8/38.8 MB 11.7 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 10.0/38.8 MB 12.2 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 13.6/38.8 MB 13.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 17.8/38.8 MB 14.2 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 22.0/38.8 MB 15.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 26.5/38.8 MB 16.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 31.2/38.8 MB 16.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.7/38.8 MB 17.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.8/38.8 MB 17.0 MB/s eta 0:00:00\n",
      "Downloading pillow_heif-0.22.0-cp311-cp311-win_amd64.whl (8.6 MB)\n",
      "   ---------------------------------------- 0.0/8.6 MB ? eta -:--:--\n",
      "   -------------------------- ------------- 5.8/8.6 MB 27.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.6/8.6 MB 25.3 MB/s eta 0:00:00\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Installing collected packages: filetype, python-dotenv, pillow-heif, opencv-python-headless, idna, requests-toolbelt, roboflow\n",
      "\n",
      "   ---------------------------------------- 0/7 [filetype]\n",
      "   ----------- ---------------------------- 2/7 [pillow-heif]\n",
      "   ----------- ---------------------------- 2/7 [pillow-heif]\n",
      "   ----------- ---------------------------- 2/7 [pillow-heif]\n",
      "  Attempting uninstall: opencv-python-headless\n",
      "   ----------- ---------------------------- 2/7 [pillow-heif]\n",
      "    Found existing installation: opencv-python-headless 4.11.0.86\n",
      "   ----------- ---------------------------- 2/7 [pillow-heif]\n",
      "    Uninstalling opencv-python-headless-4.11.0.86:\n",
      "   ----------- ---------------------------- 2/7 [pillow-heif]\n",
      "   ----------------- ---------------------- 3/7 [opencv-python-headless]\n",
      "      Successfully uninstalled opencv-python-headless-4.11.0.86\n",
      "   ----------------- ---------------------- 3/7 [opencv-python-headless]\n",
      "   ----------------- ---------------------- 3/7 [opencv-python-headless]\n",
      "   ----------------- ---------------------- 3/7 [opencv-python-headless]\n",
      "   ----------------- ---------------------- 3/7 [opencv-python-headless]\n",
      "   ----------------- ---------------------- 3/7 [opencv-python-headless]\n",
      "   ----------------- ---------------------- 3/7 [opencv-python-headless]\n",
      "   ----------------- ---------------------- 3/7 [opencv-python-headless]\n",
      "   ----------------- ---------------------- 3/7 [opencv-python-headless]\n",
      "   ----------------- ---------------------- 3/7 [opencv-python-headless]\n",
      "  Attempting uninstall: idna\n",
      "   ----------------- ---------------------- 3/7 [opencv-python-headless]\n",
      "    Found existing installation: idna 3.10\n",
      "   ----------------- ---------------------- 3/7 [opencv-python-headless]\n",
      "    Uninstalling idna-3.10:\n",
      "   ----------------- ---------------------- 3/7 [opencv-python-headless]\n",
      "      Successfully uninstalled idna-3.10\n",
      "   ----------------- ---------------------- 3/7 [opencv-python-headless]\n",
      "   ---------------------- ----------------- 4/7 [idna]\n",
      "   ---------------------- ----------------- 4/7 [idna]\n",
      "   ---------------------------- ----------- 5/7 [requests-toolbelt]\n",
      "   ---------------------------- ----------- 5/7 [requests-toolbelt]\n",
      "   ---------------------------------- ----- 6/7 [roboflow]\n",
      "   ---------------------------------- ----- 6/7 [roboflow]\n",
      "   ---------------------------------- ----- 6/7 [roboflow]\n",
      "   ---------------------------------------- 7/7 [roboflow]\n",
      "\n",
      "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pillow-heif-0.22.0 python-dotenv-1.1.0 requests-toolbelt-1.0.0 roboflow-1.1.66\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in animals-2 to coco:: 100%|██████████| 8806/8806 [00:04<00:00, 2188.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to animals-2 in coco:: 100%|██████████| 1008/1008 [00:06<00:00, 167.15it/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"H0Y0sh6WQgJi9NbXK59v\")\n",
    "project = rf.workspace(\"roboflow-100\").project(\"animals-ij5d2\")\n",
    "version = project.version(2)\n",
    "dataset = version.download(\"coco\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f95287a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets torchvision wandb --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72e0757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import wandb\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import ViTForImageClassification, ViTFeatureExtractor, Trainer, TrainingArguments\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d68894c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhabalia-taksh\u001b[0m (\u001b[33mdhabalia-taksh-mit-world-peace-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.0s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Internship_Tasks\\Maharshi_Animal-_and_Human_Detection_Model\\dst\\wandb\\run-20250614_141440-36vkyihk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dhabalia-taksh-mit-world-peace-university/animal-vit/runs/36vkyihk' target=\"_blank\">vit-animal-classifier</a></strong> to <a href='https://wandb.ai/dhabalia-taksh-mit-world-peace-university/animal-vit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dhabalia-taksh-mit-world-peace-university/animal-vit' target=\"_blank\">https://wandb.ai/dhabalia-taksh-mit-world-peace-university/animal-vit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dhabalia-taksh-mit-world-peace-university/animal-vit/runs/36vkyihk' target=\"_blank\">https://wandb.ai/dhabalia-taksh-mit-world-peace-university/animal-vit/runs/36vkyihk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dhabalia-taksh-mit-world-peace-university/animal-vit/runs/36vkyihk?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x22e12c9c9d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()\n",
    "wandb.init(project=\"animal-vit\", name=\"vit-animal-classifier\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef987bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22b9c2715754899ad05ea1a94ea4244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\dhaba\\.cache\\huggingface\\hub\\models--google--vit-base-patch16-224-in21k. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14b12728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(example):\n",
    "    image = Image.open(example['image']).convert(\"RGB\")\n",
    "    inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "    inputs['label'] = example['label']\n",
    "    return {\n",
    "        'pixel_values': inputs['pixel_values'].squeeze(),\n",
    "        'label': inputs['label']\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f01fced5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 labeled samples.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import Dataset\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "def load_coco_classification_dataset(img_dir, coco_json_path):\n",
    "    # Load COCO annotation file\n",
    "    with open(coco_json_path, 'r') as f:\n",
    "        coco = json.load(f)\n",
    "\n",
    "    # Map image_id to file name\n",
    "    img_id_to_file = {img['id']: img['file_name'] for img in coco['images']}\n",
    "\n",
    "    # Map image_id to class_id (first object only, for now)\n",
    "    img_id_to_class = {}\n",
    "    for ann in coco['annotations']:\n",
    "        if ann['image_id'] not in img_id_to_class:\n",
    "            img_id_to_class[ann['image_id']] = ann['category_id']\n",
    "\n",
    "    # Map class_id to label name\n",
    "    class_id_to_name = {cat['id']: cat['name'] for cat in coco['categories']}\n",
    "\n",
    "    # Create dataset\n",
    "    data = []\n",
    "    for img_id, fname in img_id_to_file.items():\n",
    "        if img_id in img_id_to_class:\n",
    "            label_id = img_id_to_class[img_id]\n",
    "            label = class_id_to_name[label_id]\n",
    "            data.append({\n",
    "                \"image_path\": str(Path(img_dir) / fname),\n",
    "                \"label\": label\n",
    "            })\n",
    "\n",
    "    print(f\"Found {len(data)} labeled samples.\")\n",
    "    return Dataset.from_list(data), list(sorted(set(d['label'] for d in data)))\n",
    "\n",
    "# Example usage for test set:\n",
    "test_ds, label_names = load_coco_classification_dataset(\n",
    "    img_dir=\"animals-2/test\",\n",
    "    coco_json_path=\"animals-2/test/_annotations.coco.json\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "209b99dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Couldn't find any class folder in animals-2/train.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m     dataset = Dataset.from_dict({\u001b[33m'\u001b[39m\u001b[33mimage\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(image_paths), \u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(labels)})\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset.map(transform)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m train_ds = \u001b[43mprepare_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43manimals-2/train\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m val_ds = prepare_dataset(\u001b[33m\"\u001b[39m\u001b[33manimals-2/valid\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m test_ds = prepare_dataset(\u001b[33m\"\u001b[39m\u001b[33manimals-2/test\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mprepare_dataset\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprepare_dataset\u001b[39m(path):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     folder = \u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     image_paths, labels = \u001b[38;5;28mzip\u001b[39m(*folder.samples)\n\u001b[32m      4\u001b[39m     dataset = Dataset.from_dict({\u001b[33m'\u001b[39m\u001b[33mimage\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(image_paths), \u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(labels)})\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dhaba\\anaconda3\\envs\\MH\\Lib\\site-packages\\torchvision\\datasets\\folder.py:328\u001b[39m, in \u001b[36mImageFolder.__init__\u001b[39m\u001b[34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    320\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    321\u001b[39m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[32m   (...)\u001b[39m\u001b[32m    326\u001b[39m     allow_empty: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    327\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    337\u001b[39m     \u001b[38;5;28mself\u001b[39m.imgs = \u001b[38;5;28mself\u001b[39m.samples\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dhaba\\anaconda3\\envs\\MH\\Lib\\site-packages\\torchvision\\datasets\\folder.py:149\u001b[39m, in \u001b[36mDatasetFolder.__init__\u001b[39m\u001b[34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    139\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    140\u001b[39m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[32m   (...)\u001b[39m\u001b[32m    146\u001b[39m     allow_empty: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    147\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    148\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(root, transform=transform, target_transform=target_transform)\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     classes, class_to_idx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m     samples = \u001b[38;5;28mself\u001b[39m.make_dataset(\n\u001b[32m    151\u001b[39m         \u001b[38;5;28mself\u001b[39m.root,\n\u001b[32m    152\u001b[39m         class_to_idx=class_to_idx,\n\u001b[32m   (...)\u001b[39m\u001b[32m    155\u001b[39m         allow_empty=allow_empty,\n\u001b[32m    156\u001b[39m     )\n\u001b[32m    158\u001b[39m     \u001b[38;5;28mself\u001b[39m.loader = loader\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dhaba\\anaconda3\\envs\\MH\\Lib\\site-packages\\torchvision\\datasets\\folder.py:234\u001b[39m, in \u001b[36mDatasetFolder.find_classes\u001b[39m\u001b[34m(self, directory)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfind_classes\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory: Union[\u001b[38;5;28mstr\u001b[39m, Path]) -> Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[32m    208\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[32m    209\u001b[39m \n\u001b[32m    210\u001b[39m \u001b[33;03m        directory/\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    232\u001b[39m \u001b[33;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[32m    233\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dhaba\\anaconda3\\envs\\MH\\Lib\\site-packages\\torchvision\\datasets\\folder.py:43\u001b[39m, in \u001b[36mfind_classes\u001b[39m\u001b[34m(directory)\u001b[39m\n\u001b[32m     41\u001b[39m classes = \u001b[38;5;28msorted\u001b[39m(entry.name \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m os.scandir(directory) \u001b[38;5;28;01mif\u001b[39;00m entry.is_dir())\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCouldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt find any class folder in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     45\u001b[39m class_to_idx = {cls_name: i \u001b[38;5;28;01mfor\u001b[39;00m i, cls_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(classes)}\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m classes, class_to_idx\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Couldn't find any class folder in animals-2/train."
     ]
    }
   ],
   "source": [
    "def prepare_dataset(path):\n",
    "    folder = ImageFolder(path)\n",
    "    image_paths, labels = zip(*folder.samples)\n",
    "    dataset = Dataset.from_dict({'image': list(image_paths), 'label': list(labels)})\n",
    "    return dataset.map(transform)\n",
    "\n",
    "train_ds = prepare_dataset(\"animals-2/train\")\n",
    "val_ds = prepare_dataset(\"animals-2/valid\")\n",
    "test_ds = prepare_dataset(\"animals-2/test\")\n",
    "\n",
    "label_names = ImageFolder(\"dst/animals-2/train\").classes\n",
    "print(\"Classes:\", label_names)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': train_ds,\n",
    "    'validation': val_ds,\n",
    "    'test': test_ds\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d65d668",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViTForImageClassification.from_pretrained(\n",
    "    \"google/vit-base-patch16-224-in21k\",\n",
    "    num_labels=len(label_names),\n",
    "    id2label={i: c for i, c in enumerate(label_names)},\n",
    "    label2id={c: i for i, c in enumerate(label_names)}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4056a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./vit_output\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"wandb\"  # Enable wandb logging\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3854d081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return {\"accuracy\": accuracy_score(eval_pred.label_ids, predictions)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7647b502",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['validation'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddde7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = trainer.evaluate(dataset['test'])\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcedfd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"vit-final-animal\")\n",
    "feature_extractor.save_pretrained(\"vit-final-animal\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
